
from __future__ import division
from __future__ import print_function
from __future__ import absolute_import

import argparse
import glob
import os
import io
import pandas as pd
import tensorflow as tf
import sys
import xml.etree.ElementTree as ET

from PIL import Image
from object_detection.utils import dataset_util
from collections import namedtuple, OrderedDict

def xml_to_csv(path):
    """Iterates through all .xml files (generated by labelImg) in a given directory 
    and combines them into a single Pandas dataframe.

    Parameters:
    ----------
    path : {str}
        The path containing the .xml files
    Returns:
    -------
    pandas dataFrame
        The produced dataframe
    """

    xml_list = []
    for xml_file in glob.glob(path + '/*.xml'):
        tree = ET.parse(xml_file)
        root = tree.getroot()
        for member in root.findall('object'):
            value = (root.find('filename').text,
                    int(root.find('size')[0].text),
                    int(root.find('size')[1].text),
                    member[0].text,
                    int(member[4][0].text),
                    int(member[4][1].text),
                    int(member[4][2].text),
                    int(member[4][3].text)
                    )
            xml_list.append(value)
    #the columns of the csv file in order:
    #   filename{str}: name of image file.
    #   width{int}: width of image file.
    #   height{int}: height of image file.
    #   class{str}: label of image. Image with multiple labels will be treated as separate rows.
    #   xmin{int} and ymin{int}: coordinates of upper left corner of the bounding box
    #   ymax{int} and ymax{int}: coordinates of lower right corner of the bounding box
    column_name = ['filename', 'width', 'height',
                'class', 'xmin', 'ymin', 'xmax', 'ymax']
    xml_dataframe = pd.DataFrame(xml_list, columns=column_name)
    return xml_dataframe

def class_text_to_int(row_label, label_list):
    """Iterates through the label list and return the corresponding index value
    (refer to the label_map.pbtxt id number of the labels)

    Parameters:
    ----------
    row_label : {str}
        Label of the csv row
    label_list: {list}
        List of all possible labels
    Returns:
    -------
    integer representing index value of the label
    """
    for index, label in enumerate(label_list):
        if row_label == label:
            # index + 1 because "id" from label maps starts from 1
            return index + 1
        else:
            None


def split(dataframe, group):
    """Sort the dataframe rows into groups with the same 'filename' and return them as an array.
	This is due to the fact that images may have multiple labeled objects in them which will
	be put into separate rows in the csv file.
    Parameters:
    ----------
    dataframe : pandas dataframe
        Dataframe
    group: {str}
        Column in which the groups will be sorted by
    Returns:
    -------
    array of arrays grouped by the 'filename' column in the dataframe 
    """
    data = namedtuple('data', ['filename', 'object'])
    gb = dataframe.groupby(group)
    return [data(filename, gb.get_group(x)) for filename, x in zip(gb.groups.keys(), gb.groups)]


def create_tf_example(group, path, label_list):
    """Creates a TensorFlow example to be written to a .record file used for object detection model training
	
    Parameters:
    ----------
    group : JPG file
        The image file
    path: {str}
        Path to image file
    label_list: {list}
        List of all possible labels
    Returns:
    -------
    tf.Example class object
    """
    with tf.io.gfile.GFile(os.path.join(path, '{}'.format(group.filename)), 'rb') as fid:
        encoded_jpg = fid.read()
    encoded_jpg_io = io.BytesIO(encoded_jpg)
    image = Image.open(encoded_jpg_io)
    width, height = image.size

    filename = group.filename.encode('utf8')
    image_format = b'jpg'
    # check if the image format is matching with your images.
    xmins = []
    xmaxs = []
    ymins = []
    ymaxs = []
    classes_text = []
    classes = []

    for _, row in group.object.iterrows():
        xmins.append(row['xmin'] / width)
        xmaxs.append(row['xmax'] / width)
        ymins.append(row['ymin'] / height)
        ymaxs.append(row['ymax'] / height)
        classes_text.append(row['class'].encode('utf8'))
        classes.append(class_text_to_int(row['class'],label_list))

    #populate the tf.Example object with required parameters
    tf_example = tf.train.Example(features=tf.train.Features(feature={
        'image/height': dataset_util.int64_feature(height),
        'image/width': dataset_util.int64_feature(width),
        'image/filename': dataset_util.bytes_feature(filename),
        'image/source_id': dataset_util.bytes_feature(filename),
        'image/encoded': dataset_util.bytes_feature(encoded_jpg),
        'image/format': dataset_util.bytes_feature(image_format),
        'image/object/bbox/xmin': dataset_util.float_list_feature(xmins),
        'image/object/bbox/xmax': dataset_util.float_list_feature(xmaxs),
        'image/object/bbox/ymin': dataset_util.float_list_feature(ymins),
        'image/object/bbox/ymax': dataset_util.float_list_feature(ymaxs),
        'image/object/class/text': dataset_util.bytes_list_feature(classes_text),
        'image/object/class/label': dataset_util.int64_list_feature(classes),
    }))
    return tf_example


def main(_):

    if args.input_dir == None:
        args.input_dir = os.path.dirname(os.path.abspath(__file__))
    if args.labels_file == None:
        args.labels_file = os.path.join(os.path.dirname(os.path.abspath(__file__)), "predefined_classes.txt")
    
    assert(os.path.isdir(args.input_dir))

    #CSV file creation
    xml_dataframe = xml_to_csv(args.input_dir)
    xml_dataframe.to_csv(args.csv, index=None)
    print('Successfully converted xml data to csv at: {}'.format(os.path.join(os.getcwd(),args.csv)))

    #load predefined classes
    with open(args.labels_file, 'r') as f:
        label_list = f.read().splitlines()
    
    writer = tf.io.TFRecordWriter(args.record)
    path = os.path.join(os.getcwd(), args.input_dir)
    examples = pd.read_csv(args.csv)
    grouped = split(examples, 'filename')
    #record file creation
    for group in grouped:
        tf_example = create_tf_example(group, path, label_list)
        writer.write(tf_example.SerializeToString())
    writer.close()

    print('Successfully created TensorFlow record file at: {}'.format(os.path.join(os.getcwd(),args.record)))



if __name__ == '__main__':
    parser = argparse.ArgumentParser(description="This program takes a directory of .jpg image and .xml (which contains labeled object info) \
                                                files and generate a .record and .csv file which can be used for \
                                                training an object detection model in TensorFlow.")
    parser.add_argument("-i",
                        "--input_dir",
                        help="Path to the folder where the input .jpg and .xml and files are stored. If not \
                            specified, default to finding files in current directory",
                        type=str)
    parser.add_argument("-l",
                        "--labels_file",
                        help="Path to and name of .txt file containing the labels. If not specified, default to \
                            'predefined_classes.txt' in current directory",
                         type=str)
    parser.add_argument("-c",
                        "--csv",
                        help="Path to output directory and name of .csv file. For example: --csv <PATH_TO_OUTPUT>/train.csv", 
                        type=str,
                        required = True)
    parser.add_argument("-r",
                        "--record",
                        help="Path to output directory and name of .record file.For example: --record <PATH_TO_OUTPUT>/train.record", 
                        type=str,
                        required = True)  
    args = parser.parse_args()
    tf.compat.v1.app.run()
